"use strict";
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
Object.defineProperty(exports, "__esModule", { value: true });
/**
 * Interfaces and methods for training models using tf.Tensor objects.
 */
var tfc = require("@tensorflow/tfjs-core");
var tfjs_core_1 = require("@tensorflow/tfjs-core");
var tfjs_backend_1 = require("../backend/tfjs_backend");
var base_callbacks_1 = require("../base_callbacks");
var errors_1 = require("../errors");
var logs_1 = require("../logs");
var math_utils_1 = require("../utils/math_utils");
function checkBatchSize(batchSize) {
    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), function () { return "batchSize is required to be a positive integer, but got " + batchSize; });
}
exports.checkBatchSize = checkBatchSize;
/**
 * Slice an Tensor or an Array of Tensors, by start and stop indices.
 *
 * Porting Note: The `_slice_arrays` function in PyKeras is covered by this
 *   function and `sliceArraysByIndices()` together.
 *
 * @param arrays: the input.
 * @param start: the starting index (inclusive).
 * @param stop: the stopping index (exclusive).
 * @returns The result of the slicing. If `arrays` is an `Array` of
 *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`
 *   in the same way.
 */
function sliceArrays(arrays, start, stop) {
    if (arrays == null) {
        return [null];
    }
    else if (Array.isArray(arrays)) {
        return arrays.map(function (array) { return tfjs_backend_1.sliceAlongFirstAxis(array, start, stop - start); });
    }
    else { // Tensor.
        return tfjs_backend_1.sliceAlongFirstAxis(arrays, start, stop - start);
    }
}
exports.sliceArrays = sliceArrays;
/**
 * Slice an Tensor or an Array of Tensors, by random-order indices.
 *
 * Porting Note: The `_slice_arrays` function in PyKeras is covered by this
 *   function and `sliceArrays()` together.
 *
 * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.
 *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the
 *   same fashion.
 * @param indices The indices to use for slicing along the first (batch)
 *   dimension.
 * @returns Result(s) of the slicing.
 */
function sliceArraysByIndices(arrays, indices) {
    return tfc.tidy(function () {
        if (arrays == null) {
            return null;
        }
        else if (Array.isArray(arrays)) {
            return arrays.map(function (array) { return sliceArraysByIndices(array, indices); });
        }
        else {
            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid
            //   tensor1d() calls.
            return tfjs_backend_1.gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());
        }
    });
}
exports.sliceArraysByIndices = sliceArraysByIndices;
/**
 * Returns a list of batch indices (tuples of indices).
 * @param size: Integer, total size of the data to slice into batches.
 * @param batchSize: Integer, batch size.
 * @returns An Array of [batchStart, batchEnd] tuples. batchStart is
 *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x
 *   that satisfy batchStart <= x < batchEnd.
 */
function makeBatches(size, batchSize) {
    var output = [];
    var batchStart = 0;
    var batchEnd = null;
    while (batchStart < size) {
        batchEnd = batchStart + batchSize;
        if (batchEnd >= size) {
            batchEnd = size;
        }
        output.push([batchStart, batchEnd]);
        batchStart = batchEnd;
    }
    return output;
}
exports.makeBatches = makeBatches;
/**
 * Abstract fit function for `f(ins)`.
 * @param f A Function returning a list of tensors. For training, this
 *   function is expected to perform the updates to the variables.
 * @param ins List of tensors to be fed to `f`.
 * @param outLabels List of strings, display names of the outputs of `f`.
 * @param batchSize Integer batch size or `== null` if unknown. Default : 32.
 * @param epochs Number of times to iterate over the data. Default : 1.
 * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.
 * @param callbacks List of callbacks to be called during training.
 * @param valF Function to call for validation.
 * @param valIns List of tensors to be fed to `valF`.
 * @param shuffle Whether to shuffle the data at the beginning of every
 * epoch. Default : true.
 * @param callbackMetrics List of strings, the display names of the metrics
 *   passed to the callbacks. They should be the concatenation of the
 *   display names of the outputs of `f` and the list of display names
 *   of the outputs of `valF`.
 * @param initialEpoch Epoch at which to start training (useful for
 *   resuming a previous training run). Default : 0.
 * @param stepsPerEpoch Total number of steps (batches on samples) before
 *   declaring one epoch finished and starting the next epoch. Ignored with
 *   the default value of `undefined` or `null`.
 * @param validationSteps Number of steps to run validation for (only if
 *   doing validation from data tensors). Not applicable for tfjs-layers.
 * @returns A `History` object.
 */
function fitLoop(
// Type `model` as `any` here to avoid circular dependency w/ training.ts.
// tslint:disable-next-line:no-any
model, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {
    return __awaiter(this, void 0, void 0, function () {
        var doValidation, numTrainSamples, indexArray, _a, callbackList, history, _loop_1, epoch, state_1;
        return __generator(this, function (_b) {
            switch (_b.label) {
                case 0:
                    if (batchSize == null) {
                        batchSize = 32;
                    }
                    if (epochs == null) {
                        epochs = 1;
                    }
                    if (shuffle == null) {
                        shuffle = true;
                    }
                    if (initialEpoch == null) {
                        initialEpoch = 0;
                    }
                    doValidation = false;
                    if (valF != null && valIns != null) {
                        doValidation = true;
                        // TODO(cais): verbose message.
                    }
                    if (validationSteps != null) {
                        doValidation = true;
                        if (stepsPerEpoch == null) {
                            throw new errors_1.ValueError('Can only use `validationSteps` when doing step-wise training, ' +
                                'i.e., `stepsPerEpoch` must be set.');
                        }
                    }
                    numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');
                    if (numTrainSamples != null) {
                        indexArray = math_utils_1.range(0, numTrainSamples);
                    }
                    if (verbose == null) {
                        verbose = 1;
                    }
                    _a = base_callbacks_1.configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics), callbackList = _a.callbackList, history = _a.history;
                    callbackList.setModel(model);
                    model.history = history;
                    return [4 /*yield*/, callbackList.onTrainBegin()];
                case 1:
                    _b.sent();
                    model.stopTraining_ = false;
                    _loop_1 = function (epoch) {
                        var epochLogs, epochIndexArray1D_1, batches_1, _loop_2, batchIndex, state_2;
                        return __generator(this, function (_a) {
                            switch (_a.label) {
                                case 0: return [4 /*yield*/, callbackList.onEpochBegin(epoch)];
                                case 1:
                                    _a.sent();
                                    epochLogs = {};
                                    if (!(stepsPerEpoch != null)) return [3 /*break*/, 2];
                                    throw new errors_1.NotImplementedError('stepsPerEpoch mode is not implemented yet.');
                                case 2:
                                    if (shuffle === 'batch') {
                                        throw new errors_1.NotImplementedError('batch shuffling is not implemneted yet');
                                    }
                                    else if (shuffle) {
                                        tfjs_core_1.util.shuffle(indexArray);
                                    }
                                    epochIndexArray1D_1 = tfjs_core_1.tensor1d(indexArray);
                                    batches_1 = makeBatches(numTrainSamples, batchSize);
                                    _loop_2 = function (batchIndex) {
                                        var batchLogs;
                                        return __generator(this, function (_a) {
                                            switch (_a.label) {
                                                case 0:
                                                    batchLogs = {};
                                                    return [4 /*yield*/, callbackList.onBatchBegin(batchIndex, batchLogs)];
                                                case 1:
                                                    _a.sent();
                                                    tfc.tidy(function () {
                                                        var batchStart = batches_1[batchIndex][0];
                                                        var batchEnd = batches_1[batchIndex][1];
                                                        var batchIds = tfjs_backend_1.sliceAlongFirstAxis(epochIndexArray1D_1, batchStart, batchEnd - batchStart);
                                                        batchLogs['batch'] = batchIndex;
                                                        batchLogs['size'] = batchEnd - batchStart;
                                                        // TODO(cais): In ins, train flag can be a number, instead of an
                                                        //   Tensor? Do we need to handle this in tfjs-layers?
                                                        var insBatch = sliceArraysByIndices(ins, batchIds);
                                                        var outs = f(insBatch);
                                                        for (var i = 0; i < outLabels.length; ++i) {
                                                            var label = outLabels[i];
                                                            var out = outs[i];
                                                            batchLogs[label] = out;
                                                            tfc.keep(out);
                                                            // TODO(cais): Use scope() to avoid ownership.
                                                        }
                                                        if (batchIndex === batches_1.length - 1) { // Last batch.
                                                            if (doValidation) {
                                                                var valOuts = model.testLoop(valF, valIns, batchSize);
                                                                // Porting Notes: In tfjs-layers, valOuts is always an Array.
                                                                for (var i = 0; i < outLabels.length; ++i) {
                                                                    var label = outLabels[i];
                                                                    var out = valOuts[i];
                                                                    tfc.keep(out);
                                                                    // TODO(cais): Use scope() to avoid ownership.
                                                                    epochLogs['val_' + label] = out;
                                                                }
                                                            }
                                                        }
                                                    });
                                                    return [4 /*yield*/, callbackList.onBatchEnd(batchIndex, batchLogs)];
                                                case 2:
                                                    _a.sent();
                                                    logs_1.disposeTensorsInLogs(batchLogs);
                                                    if (model.stopTraining_) {
                                                        return [2 /*return*/, "break"];
                                                    }
                                                    return [2 /*return*/];
                                            }
                                        });
                                    };
                                    batchIndex = 0;
                                    _a.label = 3;
                                case 3:
                                    if (!(batchIndex < batches_1.length)) return [3 /*break*/, 6];
                                    return [5 /*yield**/, _loop_2(batchIndex)];
                                case 4:
                                    state_2 = _a.sent();
                                    if (state_2 === "break")
                                        return [3 /*break*/, 6];
                                    _a.label = 5;
                                case 5:
                                    ++batchIndex;
                                    return [3 /*break*/, 3];
                                case 6:
                                    epochIndexArray1D_1.dispose();
                                    _a.label = 7;
                                case 7: 
                                // TODO(cais): Run validation at the end of the epoch.
                                return [4 /*yield*/, callbackList.onEpochEnd(epoch, epochLogs)];
                                case 8:
                                    // TODO(cais): Run validation at the end of the epoch.
                                    _a.sent();
                                    if (model.stopTraining_) {
                                        return [2 /*return*/, "break"];
                                    }
                                    return [2 /*return*/];
                            }
                        });
                    };
                    epoch = initialEpoch;
                    _b.label = 2;
                case 2:
                    if (!(epoch < epochs)) return [3 /*break*/, 5];
                    return [5 /*yield**/, _loop_1(epoch)];
                case 3:
                    state_1 = _b.sent();
                    if (state_1 === "break")
                        return [3 /*break*/, 5];
                    _b.label = 4;
                case 4:
                    ++epoch;
                    return [3 /*break*/, 2];
                case 5: return [4 /*yield*/, callbackList.onTrainEnd()];
                case 6:
                    _b.sent();
                    return [4 /*yield*/, model.history.syncData()];
                case 7:
                    _b.sent();
                    return [2 /*return*/, model.history];
            }
        });
    });
}
function fitTensors(
// Type `model` as `any` here to avoid circular dependency w/ training.ts.
// tslint:disable-next-line:no-any
model, x, y, args) {
    if (args === void 0) { args = {}; }
    return __awaiter(this, void 0, void 0, function () {
        var inputs, targets, inputValX, inputValY, valX, valY, sampleWeights, batchSize, checkBatchAxis, standardizedOuts, doValidation, valIns, checkBatchAxis_1, valStandardized, splitAt, originalBatchSize, ins, trainFunction, outLabels, valFunction, callbackMetrics, callbacks, out;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    if (model.isTraining) {
                        throw new Error('Cannot start training because another fit() call is ongoing.');
                    }
                    model.isTraining = true;
                    _a.label = 1;
                case 1:
                    _a.trys.push([1, , 7, 8]);
                    batchSize = args.batchSize == null ? 32 : args.batchSize;
                    checkBatchSize(batchSize);
                    checkBatchAxis = false;
                    return [4 /*yield*/, model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize)];
                case 2:
                    standardizedOuts = _a.sent();
                    inputs = standardizedOuts[0];
                    targets = standardizedOuts[1];
                    sampleWeights = standardizedOuts[2];
                    doValidation = false;
                    valIns = void 0;
                    if (!(args.validationData != null && args.validationData.length > 0)) return [3 /*break*/, 4];
                    doValidation = true;
                    if (args.validationData.length === 2) {
                        // config.validationData consists of valX and valY.
                        inputValX = args.validationData[0];
                        inputValY = args.validationData[1];
                    }
                    else if (args.validationData.length === 3) {
                        throw new errors_1.NotImplementedError('validationData including sample weights is not supported yet.');
                    }
                    else {
                        throw new errors_1.ValueError("When passing validation data, it must contain 2 (valX, valY) " +
                            "or 3 (valX, valY, valSampleWeight) items; " +
                            (args.validationData + " is invalid."));
                    }
                    checkBatchAxis_1 = true;
                    return [4 /*yield*/, model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis_1, batchSize)];
                case 3:
                    valStandardized = _a.sent();
                    valX = valStandardized[0];
                    valY = valStandardized[1];
                    valIns = valX.concat(valY);
                    return [3 /*break*/, 5];
                case 4:
                    if (args.validationSplit != null && args.validationSplit > 0 &&
                        args.validationSplit < 1) {
                        doValidation = true;
                        splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));
                        originalBatchSize = inputs[0].shape[0];
                        valX = sliceArrays(inputs, splitAt, originalBatchSize);
                        inputs = sliceArrays(inputs, 0, splitAt);
                        valY = sliceArrays(targets, splitAt, originalBatchSize);
                        targets = sliceArrays(targets, 0, splitAt);
                        // TODO(cais): Once sampleWeights becomes available, slice it to get
                        //   valSampleWeights.
                        valIns = valX.concat(valY);
                        // TODO(cais): Add useLearningPhase data properly.
                    }
                    else if (args.validationSteps != null) {
                        doValidation = true;
                        // TODO(cais): Add useLearningPhase.
                    }
                    _a.label = 5;
                case 5:
                    ins = inputs.concat(targets).concat(sampleWeights);
                    model.checkTrainableWeightsConsistency();
                    trainFunction = model.makeTrainFunction();
                    outLabels = model.getDedupedMetricsNames();
                    valFunction = void 0;
                    callbackMetrics = void 0;
                    if (doValidation) {
                        model.makeTestFunction();
                        valFunction = model.testFunction;
                        callbackMetrics =
                            outLabels.slice().concat(outLabels.map(function (n) { return 'val_' + n; }));
                    }
                    else {
                        valFunction = null;
                        valIns = [];
                        callbackMetrics = outLabels.slice();
                    }
                    callbacks = base_callbacks_1.standardizeCallbacks(args.callbacks, args.yieldEvery);
                    return [4 /*yield*/, fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null)];
                case 6:
                    out = _a.sent();
                    return [2 /*return*/, out];
                case 7:
                    model.isTraining = false;
                    // Memory clean up.
                    disposeNewTensors(inputs, x);
                    disposeNewTensors(targets, y);
                    disposeNewTensors(valX, inputValX);
                    disposeNewTensors(valY, inputValY);
                    if (sampleWeights != null) {
                        tfc.dispose(sampleWeights);
                    }
                    return [7 /*endfinally*/];
                case 8: return [2 /*return*/];
            }
        });
    });
}
exports.fitTensors = fitTensors;
/**
 * Ensure tensors all have a rank of at least 2.
 *
 * If a tensor has a rank of 1, it is dimension-expanded to rank 2.
 * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.
 */
function ensureTensorsRank2OrHigher(tensors) {
    var outs = [];
    if (tensors instanceof tfjs_core_1.Tensor) {
        tensors = [tensors];
    }
    // Make Tensors at least 2D.
    for (var i = 0; i < tensors.length; ++i) {
        var tensor = tensors[i];
        if (tensor.rank === 1) {
            outs.push(tfjs_backend_1.expandDims(tensor, 1));
        }
        else if (tensor.rank === 0) {
            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +
                '(scalar).');
        }
        else {
            outs.push(tensor);
        }
    }
    return outs;
}
exports.ensureTensorsRank2OrHigher = ensureTensorsRank2OrHigher;
/**
 * Compare a set of tensors with a reference (old) set, discard the ones
 * in the new set that are not present in the reference set.
 *
 * This method is used for memory clenaup during calls such as
 * LayersModel.fit().
 *
 * @param tensors New set which may contain Tensors not present in
 *   `refTensors`.
 * @param refTensors Reference Tensor set.
 */
// TODO(cais, kangyizhang): Deduplicate with tfjs-data.
function disposeNewTensors(tensors, refTensors) {
    if (tensors == null) {
        return;
    }
    var oldTensorIds = [];
    if (refTensors instanceof tfjs_core_1.Tensor) {
        oldTensorIds.push(refTensors.id);
    }
    else if (Array.isArray(refTensors)) {
        refTensors.forEach(function (t) { return oldTensorIds.push(t.id); });
    }
    else if (refTensors != null) {
        // `oldTensors` is a map from string name to Tensor.
        for (var name_1 in refTensors) {
            var oldTensor = refTensors[name_1];
            oldTensorIds.push(oldTensor.id);
        }
    }
    var tensorsToDispose = [];
    if (tensors instanceof tfjs_core_1.Tensor) {
        if (oldTensorIds.indexOf(tensors.id) === -1) {
            tensorsToDispose.push(tensors);
        }
    }
    else if (Array.isArray(tensors)) {
        tensors.forEach(function (t) {
            if (oldTensorIds.indexOf(t.id) === -1) {
                tensorsToDispose.push(t);
            }
        });
    }
    else if (tensors != null) {
        // `oldTensors` is a map from string name to Tensor.
        for (var name_2 in tensors) {
            var tensor = tensors[name_2];
            if (oldTensorIds.indexOf(tensor.id) === -1) {
                tensorsToDispose.push(tensor);
            }
        }
    }
    tensorsToDispose.forEach(function (t) {
        if (!t.isDisposed) {
            t.dispose();
        }
    });
}
exports.disposeNewTensors = disposeNewTensors;
//# sourceMappingURL=training_tensors.js.map